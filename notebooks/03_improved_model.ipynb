{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import *\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import joblib\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "print(\"Ready for model improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 2: Load Data and Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/preprocessed_creditcard.csv')\n",
    "train_idx = np.load('../data/train_indices.npy')\n",
    "test_idx = np.load('../data/test_indices.npy')\n",
    "baseline_model = joblib.load('../models/baseline_for_comparison.pkl')\n",
    "with open('../outputs/baseline_metrics.json', 'r') as f:\n",
    "    baseline_metrics = json.load(f)\n",
    "print(f\"Baseline: FP={baseline_metrics['false_positives']:,}, FN={baseline_metrics['false_negatives']}, AUC={baseline_metrics['roc_auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 3: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_enh = df.copy()\n",
    "v_cols = [c for c in df.columns if c.startswith('V')]\n",
    "df_enh['v_mean'] = df[v_cols].mean(axis=1)\n",
    "df_enh['v_std'] = df[v_cols].std(axis=1)\n",
    "df_enh['v_max'] = df[v_cols].max(axis=1)\n",
    "df_enh['v_min'] = df[v_cols].min(axis=1)\n",
    "df_enh['v_range'] = df_enh['v_max'] - df_enh['v_min']\n",
    "df_enh['amount_sq'] = df_enh['scaled_amount']**2\n",
    "df_enh['amount_log'] = np.log1p(np.abs(df_enh['scaled_amount'])+1)\n",
    "df_enh['time_sq'] = df_enh['scaled_time']**2\n",
    "df_enh['amt_time'] = df_enh['scaled_amount'] * df_enh['scaled_time']\n",
    "for col in ['V1','V2','V3','V4']:\n",
    "    q1, q3 = df_enh[col].quantile(0.25), df_enh[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    df_enh[f'{col}_out'] = ((df_enh[col] < q1-1.5*iqr) | (df_enh[col] > q3+1.5*iqr)).astype(int)\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "X_enh = df_enh.drop('Class', axis=1)\n",
    "y = df_enh['Class']\n",
    "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "X_train_enh, X_test_enh = X_enh.iloc[train_idx], X_enh.iloc[test_idx]\n",
    "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "print(f\"Features: {len(df.columns)-1} â†’ {len(df_enh.columns)-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 4: Train Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "improved_model = RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=15, min_samples_split=20, min_samples_leaf=10,\n",
    "    max_features='sqrt', class_weight=class_weight_dict, random_state=42, n_jobs=-1\n",
    ")\n",
    "start = time.time()\n",
    "improved_model.fit(X_train_enh, y_train)\n",
    "train_time = time.time() - start\n",
    "y_pred_imp = improved_model.predict(X_test_enh)\n",
    "y_proba_imp = improved_model.predict_proba(X_test_enh)[:, 1]\n",
    "print(f\"Trained in {train_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 5: Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({'feature': X_train_enh.columns, 'importance': improved_model.feature_importances_}).sort_values('importance', ascending=False)\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(range(15), feat_imp.head(15)['importance'].values)\n",
    "plt.yticks(range(15), feat_imp.head(15)['feature'].values)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 6: Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_base = baseline_model.predict(X_test)\n",
    "cm_b = confusion_matrix(y_test, y_pred_base)\n",
    "cm_i = confusion_matrix(y_test, y_pred_imp)\n",
    "tn_b, fp_b, fn_b, tp_b = cm_b.ravel()\n",
    "tn_i, fp_i, fn_i, tp_i = cm_i.ravel()\n",
    "\n",
    "fig = plt.figure(figsize=(18, 10))\n",
    "# Confusion Matrices\n",
    "plt.subplot(2,3,1)\n",
    "sns.heatmap(cm_b, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Baseline')\n",
    "plt.subplot(2,3,2)\n",
    "sns.heatmap(cm_i, annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Improved')\n",
    "\n",
    "# Improvements\n",
    "plt.subplot(2,3,3)\n",
    "impr = {'FP': (fp_b-fp_i)/fp_b*100 if fp_b>0 else 0, 'FN': (fn_b-fn_i)/fn_b*100 if fn_b>0 else 0}\n",
    "plt.bar(impr.keys(), impr.values(), color=['green' if v>0 else 'red' for v in impr.values()])\n",
    "plt.ylabel('Reduction %')\n",
    "plt.title('Error Reduction')\n",
    "\n",
    "# ROC Comparison\n",
    "plt.subplot(2,3,4)\n",
    "fpr_b, tpr_b, _ = roc_curve(y_test, baseline_model.predict_proba(X_test)[:,1])\n",
    "fpr_i, tpr_i, _ = roc_curve(y_test, y_proba_imp)\n",
    "auc_b, auc_i = auc(fpr_b, tpr_b), auc(fpr_i, tpr_i)\n",
    "plt.plot(fpr_b, tpr_b, 'b-', label=f'Base={auc_b:.3f}')\n",
    "plt.plot(fpr_i, tpr_i, 'g-', label=f'Imp={auc_i:.3f}')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.title('ROC Curves')\n",
    "\n",
    "# Cost Analysis\n",
    "plt.subplot(2,3,5)\n",
    "cost_b = fp_b*10 + fn_b*100\n",
    "cost_i = fp_i*10 + fn_i*100\n",
    "savings = cost_b - cost_i\n",
    "plt.bar(['Baseline','Improved','Savings'], [cost_b,cost_i,savings], color=['red','green','gold'])\n",
    "plt.ylabel('Cost ($)')\n",
    "plt.title('Financial Impact')\n",
    "\n",
    "# Summary\n",
    "ax = plt.subplot(2,3,6)\n",
    "ax.axis('off')\n",
    "ax.text(0.5, 0.5, f\"\"\"\n",
    "MODEL COMPARISON\n",
    "{'='*30}\n",
    "FP: {fp_b:,} â†’ {fp_i:,} ({(fp_i-fp_b)/fp_b*100:.1f}%)\n",
    "FN: {fn_b} â†’ {fn_i} ({(fn_i-fn_b)/fn_b*100:.1f}%)\n",
    "AUC: {auc_b:.3f} â†’ {auc_i:.3f}\n",
    "Cost: ${cost_b:,} â†’ ${cost_i:,}\n",
    "SAVINGS: ${savings:,}\n",
    "\"\"\", transform=ax.transAxes, fontsize=10, ha='center', va='center', family='monospace')\n",
    "plt.suptitle('Model Comparison Dashboard', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 7: ðŸŽ¯ LIVE DEMO TUNING ðŸŽ¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"ðŸŽ¯ LIVE DEMO: Change DEMO_PARAMETER and re-run!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ====== CHANGE THIS VALUE DURING DEMO! ======\n",
    "DEMO_PARAMETER = 100  # Try 150 or 200!\n",
    "# ============================================\n",
    "\n",
    "demo_model = RandomForestClassifier(\n",
    "    n_estimators=DEMO_PARAMETER,  # â† TUNABLE\n",
    "    max_depth=15, min_samples_split=20, min_samples_leaf=10,\n",
    "    max_features='sqrt', class_weight=class_weight_dict,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "demo_start = time.time()\n",
    "demo_model.fit(X_train_enh, y_train)\n",
    "demo_time = time.time() - demo_start\n",
    "y_pred_d = demo_model.predict(X_test_enh)\n",
    "y_proba_d = demo_model.predict_proba(X_test_enh)[:,1]\n",
    "cm_d = confusion_matrix(y_test, y_pred_d)\n",
    "tn_d, fp_d, fn_d, tp_d = cm_d.ravel()\n",
    "auc_d = roc_auc_score(y_test, y_proba_d)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "# Confusion Matrix\n",
    "sns.heatmap(cm_d, annot=True, fmt='d', cmap='Purples', ax=axes[0])\n",
    "axes[0].set_title(f'n_estimators={DEMO_PARAMETER}')\n",
    "# Performance Comparison\n",
    "x = np.arange(3)\n",
    "axes[1].bar(x-0.25, [fp_b, fn_b, auc_b*100], 0.25, label='Baseline', color='red')\n",
    "axes[1].bar(x, [fp_i, fn_i, auc_i*100], 0.25, label='Default(100)', color='green')\n",
    "axes[1].bar(x+0.25, [fp_d, fn_d, auc_d*100], 0.25, label=f'Demo({DEMO_PARAMETER})', color='gold')\n",
    "axes[1].set_xticks(x)\n",
    "axes[1].set_xticklabels(['FP', 'FN', 'AUCÃ—100'])\n",
    "axes[1].legend()\n",
    "# Complexity vs Performance\n",
    "axes[2].plot([50,100,DEMO_PARAMETER], [auc_b*0.98, auc_i, auc_d], 'go-')\n",
    "axes[2].set_xlabel('n_estimators')\n",
    "axes[2].set_ylabel('AUC')\n",
    "axes[2].scatter([DEMO_PARAMETER], [auc_d], s=200, color='gold', edgecolor='black')\n",
    "plt.suptitle(f'Live Tuning: n_estimators={DEMO_PARAMETER}', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\"\"\n",
    "Performance with n_estimators={DEMO_PARAMETER}:\n",
    "Time: {demo_time:.2f}s | FP: {fp_d} | FN: {fn_d} | AUC: {auc_d:.3f}\n",
    "Change vs default: FP {(fp_d-fp_i)/fp_i*100:+.1f}%, AUC {(auc_d-auc_i)*100:+.2f}pp\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell 8: Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "os.makedirs('../outputs', exist_ok=True)\n",
    "joblib.dump(improved_model, '../models/improved_random_forest.pkl')\n",
    "metrics_imp = {\n",
    "    'accuracy': float(accuracy_score(y_test, y_pred_imp)),\n",
    "    'precision': float(precision_score(y_test, y_pred_imp)),\n",
    "    'recall': float(recall_score(y_test, y_pred_imp)),\n",
    "    'f1_score': float(f1_score(y_test, y_pred_imp)),\n",
    "    'roc_auc': float(auc_i),\n",
    "    'false_positives': int(fp_i),\n",
    "    'false_negatives': int(fn_i),\n",
    "    'total_cost': float(cost_i),\n",
    "    'savings_vs_baseline': float(savings),\n",
    "    'fp_reduction_pct': float((fp_b-fp_i)/fp_b*100) if fp_b>0 else 0\n",
    "}\n",
    "with open('../outputs/improved_metrics.json', 'w') as f:\n",
    "    json.dump(metrics_imp, f, indent=2)\n",
    "feat_imp.to_csv('../outputs/feature_importance.csv', index=False)\n",
    "\n",
    "print(f\"\"\"\n",
    "{'='*60}\n",
    "DEMO COMPLETE!\n",
    "FP reduced: {(fp_b-fp_i)/fp_b*100:.1f}%\n",
    "Savings: ${savings:,}\n",
    "AUC: {auc_b:.3f} â†’ {auc_i:.3f}\n",
    "\n",
    "Remember: Cell 7 is the LIVE DEMO!\n",
    "Change DEMO_PARAMETER to 150 or 200 and re-run!\n",
    "{'='*60}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}